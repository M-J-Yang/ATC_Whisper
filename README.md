# ATC è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ

åŸºäº Whisper çš„èˆªç©ºäº¤é€šç®¡åˆ¶ (ATC) è¯­éŸ³è¯†åˆ«ç³»ç»Ÿï¼Œæ”¯æŒå‘½ä»¤è¡Œå’Œ Web ç•Œé¢ä¸¤ç§ä½¿ç”¨æ–¹å¼ã€‚

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

- **æ•°æ®é›†**: ATCOSIM (10å°æ—¶ï¼Œ10078æ¡è¯è¯­)
- **æ¨¡å‹**: OpenAI Whisper-base
- **ä½¿ç”¨æ–¹å¼**: å‘½ä»¤è¡Œ + Web ç•Œé¢
- **ç›®æ ‡**: å¹³è¡¡ç²¾åº¦(WER ~45%)å’Œæ¨ç†é€Ÿåº¦(RTF ~0.12)

## ğŸ“ é¡¹ç›®ç»“æ„

```
demo/
â”œâ”€â”€ core/                      # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ inference.py          # Whisper æ¨ç†å¼•æ“
â”‚   â”œâ”€â”€ preprocess.py         # æ•°æ®é¢„å¤„ç†
â”‚   â”œâ”€â”€ train.py              # æ¨¡å‹è®­ç»ƒ
â”‚   â””â”€â”€ atc_decoder.py        # ATC è¯æ±‡çº¦æŸè§£ç å™¨
â”œâ”€â”€ backend/                  # Web åç«¯
â”‚   â”œâ”€â”€ app.py               # FastAPI åº”ç”¨
â”‚   â””â”€â”€ inference_service.py  # æ¨ç†æœåŠ¡
â”œâ”€â”€ frontend/                 # Web å‰ç«¯
â”‚   â””â”€â”€ src/components/      # React ç»„ä»¶
â”œâ”€â”€ scripts/                  # å‘½ä»¤è¡Œå·¥å…·
â”‚   â”œâ”€â”€ inference_single.py  # å•æ¡æ¨ç†
â”‚   â””â”€â”€ inference_interactive.py # äº¤äº’å¼æ¨ç†
â”œâ”€â”€ models/                   # æ¨¡å‹æ–‡ä»¶
â”œâ”€â”€ config.yaml              # é…ç½®æ–‡ä»¶
â””â”€â”€ start_all.ps1            # ä¸€é”®å¯åŠ¨
```

è¯¦ç»†ç»“æ„è§ [FILE_STRUCTURE.md](FILE_STRUCTURE.md) æˆ– [PROJECT_STRUCTURE.md](PROJECT_STRUCTURE.md)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šWeb åº”ç”¨ï¼ˆæ¨èï¼‰

#### 1. å®‰è£…ä¾èµ–
```powershell
.\install_dependencies.ps1
```

#### 2. ä¸€é”®å¯åŠ¨
```powershell
.\start_all.ps1
```

ç³»ç»Ÿä¼šè‡ªåŠ¨å¯åŠ¨åç«¯ (http://localhost:8000) å’Œå‰ç«¯ (http://localhost:3000)

#### 3. ä½¿ç”¨ç•Œé¢
1. ç‚¹å‡»"åŠ è½½æ¨¡å‹"
2. é€‰æ‹©æ¨ç†æ–¹å¼ï¼šå•æ¡æ¨ç†/å®æ—¶è¯†åˆ«
3. æŸ¥çœ‹ç»“æœå¹¶å¯¼å‡º

è¯¦è§ [README_WEB.md](README_WEB.md)

### æ–¹å¼äºŒï¼šå‘½ä»¤è¡Œå·¥å…·

#### å•æ¬¡æ¨ç†
```bash
python scripts/inference_single.py
```

#### äº¤äº’å¼æ¨ç†
```bash
python scripts/inference_interactive.py
```

### æ–¹å¼ä¸‰ï¼šè®­ç»ƒæ¨¡å‹

#### 1ï¸âƒ£ ç¯å¢ƒå®‰è£…

```bash
# Python 3.10+
python -m venv venv
source venv/Scripts/activate  # Windows: venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

#### 2ï¸âƒ£ æ•°æ®é¢„å¤„ç†

```bash
python core/preprocess.py
```

**æµç¨‹**:
- åŠ è½½ `fulldata.csv` å…ƒæ•°æ®
- åŠ è½½å¹¶é‡é‡‡æ ·éŸ³é¢‘åˆ°16kHz
- æ ‡å‡†åŒ–è½¬å½•æ–‡æœ¬ (ç§»é™¤ ~p ~s ~a ç‰¹æ®Šæ ‡è®°)
- æŒ‰è¯´è¯äººåˆ†å±‚åˆ’åˆ†æ•°æ®é›† (train 80% / val 10% / test 10%)
- ä¿å­˜æ ‡å‡†åŒ–çš„JSONæ¸…å•

**è¾“å‡º**:
```
outputs/processed_data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ *.wav (é‡é‡‡æ ·çš„éŸ³é¢‘)
â”‚   â””â”€â”€ train_manifest.json
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ *.wav
â”‚   â””â”€â”€ val_manifest.json
â””â”€â”€ test/
    â”œâ”€â”€ *.wav
    â””â”€â”€ test_manifest.json
```

#### 3ï¸âƒ£ æ¨¡å‹è®­ç»ƒ

```bash
# åŸºç¡€è®­ç»ƒ
python core/train.py

# è§£å†»æœ€åNå±‚ç¼–ç å™¨
python core/train.py --unfreeze-encoder-layers 2

# ä½¿ç”¨Adapterå±‚
python core/train.py --use-adapter true
```

**ç‰¹ç‚¹**:
- âœ… è‡ªåŠ¨æ£€æµ‹GPUï¼Œå¯ç”¨DDPåˆ†å¸ƒå¼è®­ç»ƒ
- âœ… çµæ´»çš„ç¼–ç å™¨å†»ç»“ç­–ç•¥ï¼ˆå†»ç»“/éƒ¨åˆ†/å…¨é‡å¾®è°ƒï¼‰
- âœ… æ”¯æŒAdapterå±‚å‚æ•°é«˜æ•ˆå¾®è°ƒ
- âœ… FP32ç²¾åº¦è®­ç»ƒï¼ˆWindowså…¼å®¹ï¼Œå¯é€šè¿‡é…ç½®å¯ç”¨FP16ï¼‰
- âœ… è¯„ä¼°æ­¥é•¿å¯é…ç½®
- âœ… è‡ªåŠ¨ä¿å­˜æœ€å¥½çš„æ¨¡å‹

**è®­ç»ƒé…ç½®** (æ¥è‡ª `config.yaml`):
- Batch Size: 4 (å¯æ ¹æ®æ˜¾å­˜è°ƒæ•´)
- Learning Rate: 1e-5
- Epochs: 10
- Warmup Steps: 500
- Mixed Precision: FP32 (ç¨³å®šæ€§ä¼˜å…ˆ)

**è¾“å‡º**:
```
outputs/
â”œâ”€â”€ models/final_model/
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â”œâ”€â”€ preprocessor_config.json
â”‚   â””â”€â”€ tokenizer_vocab.json
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ tensorboard events
â””â”€â”€ checkpoints/
    â””â”€â”€ checkpoint-*/ (ä¸­é—´æ£€æŸ¥ç‚¹)
```

#### 4ï¸âƒ£ æ¨ç†å’Œè¯„ä¼°

ä½¿ç”¨æ ¸å¿ƒæ¨ç†å¼•æ“ï¼š
```bash
# å•ä¸ªæ–‡ä»¶æ¨ç†
python core/inference.py \
    --model_path models/final_model \
    --audio_path /path/to/audio.wav

# æ•´ä¸ªæµ‹è¯•é›†è¯„ä¼°
python core/inference.py \
    --model_path models/final_model \
    --dataset_dir processed_data \
    --split test \
    --output_dir outputs/results
```

æˆ–ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·ï¼ˆæ›´æ–¹ä¾¿ï¼‰ï¼š
```bash
# å•æ¡æ¨ç†
python scripts/inference_single.py

# äº¤äº’å¼æ¨ç†
python scripts/inference_interactive.py
```

#### è¯„ä¼°å¸¦è¯è¡¨çº¦æŸï¼ˆç”¨äºå¯¹æ¯”ï¼‰
```bash
python inference.py \
    --model_path outputs/models/final_model \
    --dataset_dir outputs/processed_data \
    --split test \
    --output_dir outputs/results_constrained \
    --vocab_constraint "ATCOSIM/TXTdata/wordlist.txt"
```

**è¾“å‡º**:
```
outputs/results/
â”œâ”€â”€ evaluation_report.json (è¯¦ç»†æŒ‡æ ‡: WER, CER, æŒ‰è¯´è¯äººåˆ†æ)
â””â”€â”€ transcription_results.csv (è½¬å½•ç»“æœ)
```

## ğŸ“Š é…ç½®å‚æ•°

ç¼–è¾‘ `config.yaml` è°ƒæ•´:

```yaml
# æ•°æ®é…ç½®
data:
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  target_sr: 16000
  normalize: true  # éŸ³é‡å½’ä¸€åŒ–

  # æ•°æ®å¢å¼ºé…ç½®
  augmentation:
    enabled: true
    speed_perturb: [0.9, 1.1]  # é€Ÿåº¦æ‰°åŠ¨: Â±10%
    # SpecAugmentå‚æ•°: freq_mask_param, time_mask_param

# æ¨¡å‹é…ç½®
model:
  type: "whisper"
  whisper_size: "base"  # tiny|base|small|medium|large
  use_atc_vocab_constraint: true

# è®­ç»ƒé…ç½®
training:
  epochs: 10
  batch_size: 4  # æ ¹æ®æ˜¾å­˜è°ƒæ•´ (4090æ¨è4)
  gradient_accumulation_steps: 4
  learning_rate: 1e-5
  warmup_steps: 500
  weight_decay: 0.01

  # DDPå¤šGPUé…ç½®
  distributed: true
  device_ids: [0]  # ä¿®æ”¹ä¸ºå®é™…GPUæ•°é‡

  # è¯„ä¼°å’Œä¿å­˜
  eval_steps: 1000
  save_steps: 1000

# æ¨ç†é…ç½®
inference:
  beam_size: 5        # æŸ¬å¯¨æœç´¢å®½åº¦
  max_length: 224     # æœ€å¤§ç”Ÿæˆé•¿åº¦
  temperature: 0.0    # 0=ç¡®å®šæ€§, >0=éšæœº
  language: "en"      # en|zh|ç­‰

# ç³»ç»Ÿé…ç½®
system:
  seed: 42
  num_workers: 4      # æ•°æ®åŠ è½½è¿›ç¨‹æ•°
  max_grad_norm: 1.0
  mixed_precision: "fp32"  # fp32|fp16|bf16
```

### å…³é”®å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | æ¨èå€¼ |
|------|------|--------|
| `batch_size` | æ¯å¼ GPUçš„æ‰¹æ¬¡å¤§å° | 4 (RTX4090), 2 (RTX3090) |
| `grad_accumulation_steps` | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° | 4 (ç­‰æ•ˆbatch=16) |
| `learning_rate` | å­¦ä¹ ç‡ | 1e-5 (ä¿å®ˆ) ~ 5e-5 (æ¿€è¿›) |
| `speed_perturb` | é€Ÿåº¦æ‰°åŠ¨èŒƒå›´ | [0.9, 1.1] (Â±10%) |
| `beam_size` | æŸæœç´¢å®½åº¦ | 5 (å¹³è¡¡), 3 (å¿«é€Ÿ), 10 (ç²¾åº¦) |
| `max_length` | æœ€å¤§ç”Ÿæˆé•¿åº¦ | 224 (Whisperæ ‡å‡†) |

## ğŸ“ˆ æ€§èƒ½é¢„æœŸ

| é˜¶æ®µ | WER | æ¨ç†é€Ÿåº¦ | æ˜¾å­˜å ç”¨ |
|------|-----|---------|---------|
| åŸºç¡€æ¨¡å‹(æ— å¾®è°ƒ) | ~75% | 3.2x RT | 6GB |
| å¾®è°ƒå(å†»ç»“ç¼–ç ) | ~48% | 3.5x RT | 8GB |
| å¾®è°ƒå(å…¨é‡) | ~42% | 3.5x RT | 16GB |
| +è¯è¡¨çº¦æŸ | ~38% | 2.8x RT | 8GB |

**è¯´æ˜**:
- RT = Real-Time (å¤„ç†1å°æ—¶éŸ³é¢‘éœ€è¦çš„æ—¶é—´)
- æ˜¾å­˜å ç”¨æŒ‡å•GPU, batch_size=4
- è¯è¡¨çº¦æŸæ˜¯åå¤„ç†ï¼Œé›¶é¢å¤–æ˜¾å­˜å¼€é”€

## âœ¨ æœ€è¿‘æ›´æ–° (v1.1)

### æ–°å¢åŠŸèƒ½
- âœ… **æ•°æ®å¢å¼º**: å®ç°é€Ÿåº¦æ‰°åŠ¨ (Â±5-10%) å’Œ SpecAugment
- âœ… **çµæ´»çš„ç¼–ç å™¨æ§åˆ¶**:
  - `--unfreeze-encoder-layers N` è§£å†»æœ€åNå±‚
  - `--unfreeze-encoder-layers -1` å…¨é‡å¾®è°ƒ
- âœ… **è¯è¡¨çº¦æŸ**: `--vocab_constraint` å‚æ•°ç”¨äºATCåŸŸçº¦æŸ
- âœ… **æœåŠ¡å™¨éƒ¨ç½²**: å®Œæ•´çš„éƒ¨ç½²æŒ‡å—å’Œèµ„æºéœ€æ±‚è¡¨
- âœ… **Baselineå¯¹æ¯”**: æ ‡å‡†åŒ–çš„è¯„ä¼°æµç¨‹å’Œå¯¹æ¯”æ¡†æ¶

### æ”¹è¿›
- æ”¹è¿›text normalizationæ–‡æ¡£ï¼ˆ~p=åœé¡¿, ~s=ä¸æ¸…, ~a=å£éŸ³ï¼‰
- å®Œå–„äº†æœåŠ¡å™¨éƒ¨ç½²æµç¨‹å’Œæ—¥å¿—ç›‘æ§å»ºè®®
- æ·»åŠ äº†FP32/FP16/BF16ç²¾åº¦é€‰é¡¹è¯´æ˜

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
demo/
â”œâ”€â”€ config.yaml              # å…¨å±€é…ç½®
â”œâ”€â”€ requirements.txt         # Pythonä¾èµ–
â”œâ”€â”€ preprocess.py            # æ•°æ®é¢„å¤„ç†è„šæœ¬
â”œâ”€â”€ train.py                 # è®­ç»ƒè„šæœ¬ (æ”¯æŒDDP)
â”œâ”€â”€ inference.py             # æ¨ç†å’Œè¯„ä¼°è„šæœ¬
â”œâ”€â”€ run.sh                   # å®Œæ•´æµç¨‹è„šæœ¬
â”œâ”€â”€ README.md                # æœ¬æ–‡æ¡£
â”œâ”€â”€ ATCOSIM/                 # æ•°æ®é›†
â”‚   â”œâ”€â”€ WAVdata/             # éŸ³é¢‘æ–‡ä»¶
â”‚   â”œâ”€â”€ TXTdata/
â”‚   â”‚   â”œâ”€â”€ fulldata.csv     # å…ƒæ•°æ®
â”‚   â”‚   â””â”€â”€ wordlist.txt     # ATCè¯æ±‡è¡¨
â”‚   â”œâ”€â”€ HTMLdata/
â”‚   â””â”€â”€ DOC/
â””â”€â”€ outputs/
    â”œâ”€â”€ processed_data/      # é¢„å¤„ç†çš„æ•°æ®
    â”œâ”€â”€ models/              # è®­ç»ƒçš„æ¨¡å‹
    â”œâ”€â”€ logs/                # TensorBoardæ—¥å¿—
    â””â”€â”€ results/             # æ¨ç†ç»“æœ
```

## ğŸ” å…³é”®ç‰¹æ€§

### 1. æ•°æ®é¢„å¤„ç†
- âœ… è‡ªåŠ¨ç§»é™¤ATCç‰¹æ®Šæ ‡è®° (~p=åœé¡¿, ~s=ä¸æ¸…, ~a=å£éŸ³)
- âœ… éŸ³é¢‘é‡é‡‡æ ·å’Œå½’ä¸€åŒ– (16kHz)
- âœ… **æ•°æ®å¢å¼º**: é€Ÿåº¦æ‰°åŠ¨ (Â±5-10%) å’Œ SpecAugment
- âœ… åˆ†å±‚æ•°æ®åˆ’åˆ† (æŒ‰è¯´è¯äºº)
- âœ… è´¨é‡æ£€æŸ¥ (ç§»é™¤æŸåçš„éŸ³é¢‘)

### 2. çµæ´»çš„è®­ç»ƒç­–ç•¥
- âœ… ç¼–ç å™¨å†»ç»“ï¼ˆå¿«é€Ÿå¾®è°ƒï¼‰
- âœ… éƒ¨åˆ†è§£å†»æœ€åNå±‚ï¼ˆå¹³è¡¡ç²¾åº¦å’Œé€Ÿåº¦ï¼‰
- âœ… å…¨é‡å¾®è°ƒï¼ˆæœ€é«˜ç²¾åº¦ï¼‰
- âœ… DDPå¤šGPUåˆ†å¸ƒå¼è®­ç»ƒ
- âœ… æ¢¯åº¦ç´¯ç§¯æ”¯æŒ
- âœ… FP32/FP16/BF16ç²¾åº¦é€‰é¡¹

### 3. æ¨ç†ä¼˜åŒ–
- âœ… å•æ–‡ä»¶å’Œæ‰¹é‡æ¨ç†
- âœ… **ATCè¯è¡¨çº¦æŸ**ï¼ˆåå¤„ç†ï¼Œæé«˜åŸŸç‰¹å®šç²¾åº¦ï¼‰
- âœ… å¯è°ƒçš„Beam Searchå®½åº¦
- âœ… GPUåŠ é€Ÿæ¨ç†

### 4. è¯„ä¼°æŒ‡æ ‡
- âœ… è¯é”™ç‡ (WER)
- âœ… å­—é”™ç‡ (CER)
- âœ… æŒ‰è¯´è¯äººçš„WERåˆ†æ
- âœ… è¯¦ç»†çš„è½¬å½•ç»“æœå¯¼å‡º (CSV/JSON)

## ğŸ–¥ï¸ æœåŠ¡å™¨éƒ¨ç½²

### å¿«é€Ÿéƒ¨ç½²æµç¨‹

```bash
# 1. å…‹éš†/ä¸Šä¼ é¡¹ç›®
cd /path/to/project

# 2. åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒ
python3.10 -m venv venv
source venv/bin/activate  # Linux/Mac

# 3. å®‰è£…ä¾èµ–ï¼ˆç¡®ä¿torch/torchaudioç‰ˆæœ¬ä¸€è‡´ï¼‰
pip install -r requirements.txt

# 4. éªŒè¯CUDA/GPU
python -c "import torch; print(torch.cuda.is_available()); print(torch.cuda.device_count())"

# 5. æ•°æ®é¢„å¤„ç†ï¼ˆå•æ¬¡è¿è¡Œï¼‰
python preprocess.py

# 6. å¯åŠ¨è®­ç»ƒï¼ˆæ”¯æŒåå°è¿è¡Œï¼‰
nohup python train.py > train.log 2>&1 &

# 7. ç›‘æ§è®­ç»ƒè¿›åº¦
tail -f train.log
tensorboard --logdir=logs/

# 8. è¯„ä¼°æ¨¡å‹
python inference.py \
    --model_path models/final_model \
    --dataset_dir outputs/processed_data \
    --split test \
    --output_dir outputs/results
```

### å…³é”®éƒ¨ç½²å»ºè®®

1. **ä¾èµ–ç®¡ç†**: ä¿è¯ `torch==2.x` å’Œ `torchaudio==2.x` ç‰ˆæœ¬ä¸€è‡´
2. **æ˜¾å­˜ç®¡ç†**: æ ¹æ®GPUæ˜¾å­˜è°ƒæ•´ `batch_size` (4090 æ¨èè®¾ä¸º4)
3. **æ•°æ®è·¯å¾„**: æ›´æ–° `config.yaml` ä¸­çš„ç»å¯¹è·¯å¾„
4. **åå°è¿è¡Œ**: ä½¿ç”¨ `nohup` æˆ– `tmux/screen` ä¿æŒè¿›ç¨‹
5. **æ—¥å¿—ç›‘æ§**: å®šæœŸæ£€æŸ¥ `logs/` å’Œ `train.log`

### æœåŠ¡å™¨èµ„æºéœ€æ±‚

| é…ç½® | GPU | æ˜¾å­˜ | CPU | å†…å­˜ |
|------|-----|------|-----|------|
| æœ€å° | 1x RTX3090 | 24GB | 8æ ¸ | 32GB |
| æ¨è | 2x A100 | 80GB | 16æ ¸ | 128GB |
| å¼€å‘ | 1x RTX4090 | 24GB | 8æ ¸ | 64GB |

## ğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### æé«˜ç²¾åº¦
1. å¢åŠ è®­ç»ƒè½®æ•°: `training.epochs: 15-20`
2. ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹: `model.whisper_size: "small"` or `"medium"`
3. **å¯ç”¨æ•°æ®å¢å¼º**: `data.augmentation.enabled: true` (é€Ÿåº¦æ‰°åŠ¨+SpecAugment)
4. è§£å†»ç¼–ç å™¨å±‚: `python train.py --unfreeze-encoder-layers 4`
5. è°ƒæ•´å­¦ä¹ ç‡: `training.learning_rate: 5e-5`

### åŠ é€Ÿæ¨ç†
1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹: `model.whisper_size: "tiny"` or `"base"`
2. å‡å°Beam Searchå®½åº¦: `inference.beam_size: 3`
3. **åº”ç”¨è¯è¡¨çº¦æŸ**: å‡å°‘æœç´¢ç©ºé—´ï¼ŒåŠ é€Ÿè§£ç 
4. é‡åŒ–æ¨¡å‹ (éœ€è¦é¢å¤–å®ç°)

### å‡å°‘æ˜¾å­˜å ç”¨
1. é™ä½batch size: `training.batch_size: 4`
2. å¯ç”¨æ¢¯åº¦æ£€æŸ¥: åœ¨train.pyä¸­è®¾ç½®
3. ä½¿ç”¨æ›´å°æ¨¡å‹
4. **ä½¿ç”¨Adapterå±‚**: `python train.py --use-adapter true` (å‚æ•°å‡å°‘90%)

## ğŸ“Š Baselineå¯¹æ¯”ä¸è¯„ä¼°

### å»ºç«‹Baseline (å¾®è°ƒå‰)

```bash
# 1. ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹(æ— å¾®è°ƒ)è¿›è¡Œè¯„ä¼°
python inference.py \
    --model_path "openai/whisper-base" \
    --dataset_dir outputs/processed_data \
    --split test \
    --output_dir outputs/baseline

# è¾“å‡º: baseline WER
```

### è¯„ä¼°å¾®è°ƒåçš„æ¨¡å‹

```bash
# 2. ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹è¯„ä¼°ï¼ˆç›¸åŒçš„normalizationï¼‰
python inference.py \
    --model_path models/final_model \
    --dataset_dir outputs/processed_data \
    --split test \
    --output_dir outputs/finetuned
```

### å¯¹æ¯”åˆ†æ

```bash
# 3. å¯¹æ¯”ä¸¤ä¸ªè¯„ä¼°ç»“æœ
# æ¯”è¾ƒ outputs/baseline/evaluation_report.json å’Œ outputs/finetuned/evaluation_report.json
# å…³é”®æŒ‡æ ‡:
#   - WERé™å¹…: (baseline_wer - finetuned_wer) / baseline_wer
#   - CERé™å¹…
#   - æŒ‰è¯´è¯äººåˆ†æ (speaker_wers)
```

**ç¤ºä¾‹å¯¹æ¯”**:
```
| æ¨¡å¼ | WER | CER | æ”¹è¿› |
|------|-----|-----|------|
| Baseline (æ— å¾®è°ƒ) | 75.2% | 32.1% | - |
| å¾®è°ƒå (10å°æ—¶) | 48.3% | 18.5% | 36% |
| +è¯è¡¨çº¦æŸ | 42.1% | 16.2% | 44% |
```

### ç¡®ä¿å…¬å¹³å¯¹æ¯”

âš ï¸ **é‡è¦**: ç¡®ä¿baselineå’Œå¾®è°ƒæ¨¡å‹ä½¿ç”¨**ç›¸åŒçš„**:
1. âœ… Text normalization (éƒ½ç»è¿‡ `preprocess.py` çš„normalize_transcription)
2. âœ… æ•°æ®åˆ’åˆ† (ç›¸åŒçš„test_manifest.json)
3. âœ… è¯„ä¼°å‚æ•° (beam_size, max_lengthç­‰)
4. âœ… æ¨ç†é…ç½® (FP32/FP16, è®¾å¤‡ç­‰)

## ğŸ› æ•…éšœæ’é™¤

### CUDA OOMé”™è¯¯
```python
# é™ä½batch size in config.yaml
training:
  batch_size: 4  # ä»8é™è‡³4
  gradient_accumulation_steps: 4  # å¢åŠ ç´¯ç§¯æ­¥æ•°
```

### æ•°æ®é›†åŠ è½½å¤±è´¥
```bash
# æ£€æŸ¥æ•°æ®é›†è·¯å¾„
ls -la "d:\NPU_works\è¯­éŸ³\demo\ATCOSIM"

# éªŒè¯fulldata.csv
head -5 "d:\NPU_works\è¯­éŸ³\demo\ATCOSIM\TXTdata\fulldata.csv"
```

### æ¨¡å‹åŠ è½½å¤±è´¥
```bash
# ç¡®ä¿æ¨¡å‹ç›®å½•æ­£ç¡®
ls -la outputs/models/final_model/

# é‡æ–°ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
python -c "from transformers import WhisperForConditionalGeneration; \
    WhisperForConditionalGeneration.from_pretrained('openai/whisper-base')"
```

## ğŸ“š å‚è€ƒèµ„æº

- [OpenAI Whisper](https://github.com/openai/whisper)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)
- [ATCOSIM Corpus](https://www.uni-sb.de/en/research/projects/atcosim)
- [WERè®¡ç®—æ–¹æ³•](https://en.wikipedia.org/wiki/Word_error_rate)

## ğŸ“ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªMITè®¸å¯è¯ã€‚ATCOSIMæ•°æ®é›†æœ‰å…¶ä¸“å±è®¸å¯è¯ï¼Œè¯·æŸ¥çœ‹ `ATCOSIM/DOC/` ç›®å½•ã€‚

## ğŸ‘¨â€ğŸ’¼ ä½œè€…

Created with â¤ï¸ for ATC Speech Recognition
